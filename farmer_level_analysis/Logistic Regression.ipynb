{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notebook to use logistic regression on the Animal Future survey data to predict farmers adoption."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data upload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_data = \"./survey_data/AF_survey_data_30.xlsx\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AdoptedSBP</th>\n",
       "      <th>PastureSurface</th>\n",
       "      <th>CattlePercentage</th>\n",
       "      <th>Distrito</th>\n",
       "      <th>Concelho</th>\n",
       "      <th>FarmerSince</th>\n",
       "      <th>PercentRentedLand</th>\n",
       "      <th>LegalForm</th>\n",
       "      <th>HighestEducationalDegree</th>\n",
       "      <th>HighestAgriculturalEducationalDegree</th>\n",
       "      <th>ExpectationFamilySuccession</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FARM_ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>PT02</th>\n",
       "      <td>0</td>\n",
       "      <td>364.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Setúbal</td>\n",
       "      <td>Grândola</td>\n",
       "      <td>29</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Individual</td>\n",
       "      <td>Undergraduate</td>\n",
       "      <td>Undergraduate</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PT13</th>\n",
       "      <td>1</td>\n",
       "      <td>542.58</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Portalegre</td>\n",
       "      <td>Avis</td>\n",
       "      <td>11</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Associated</td>\n",
       "      <td>Undergraduate</td>\n",
       "      <td>Undergraduate</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PT15</th>\n",
       "      <td>1</td>\n",
       "      <td>262.70</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Portalegre</td>\n",
       "      <td>Monforte</td>\n",
       "      <td>11</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Associated</td>\n",
       "      <td>Undergraduate</td>\n",
       "      <td>Undergraduate</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PT16</th>\n",
       "      <td>0</td>\n",
       "      <td>23.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Évora</td>\n",
       "      <td>Évora</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Individual</td>\n",
       "      <td>Undergraduate</td>\n",
       "      <td>Undergraduate</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PT17</th>\n",
       "      <td>1</td>\n",
       "      <td>250.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Évora</td>\n",
       "      <td>Montemor</td>\n",
       "      <td>10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Associated</td>\n",
       "      <td>Undergraduate</td>\n",
       "      <td>None</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         AdoptedSBP  PastureSurface  CattlePercentage    Distrito  Concelho  \\\n",
       "FARM_ID                                                                       \n",
       "PT02              0          364.00               0.0     Setúbal  Grândola   \n",
       "PT13              1          542.58               1.0  Portalegre      Avis   \n",
       "PT15              1          262.70               1.0  Portalegre  Monforte   \n",
       "PT16              0           23.00               1.0       Évora     Évora   \n",
       "PT17              1          250.00               1.0       Évora  Montemor   \n",
       "\n",
       "         FarmerSince  PercentRentedLand   LegalForm HighestEducationalDegree  \\\n",
       "FARM_ID                                                                        \n",
       "PT02              29                0.0  Individual            Undergraduate   \n",
       "PT13              11                0.0  Associated            Undergraduate   \n",
       "PT15              11                1.0  Associated            Undergraduate   \n",
       "PT16               3                1.0  Individual            Undergraduate   \n",
       "PT17              10                1.0  Associated            Undergraduate   \n",
       "\n",
       "        HighestAgriculturalEducationalDegree ExpectationFamilySuccession  \n",
       "FARM_ID                                                                   \n",
       "PT02                           Undergraduate                         Yes  \n",
       "PT13                           Undergraduate                         Yes  \n",
       "PT15                           Undergraduate                         Yes  \n",
       "PT16                           Undergraduate                         Yes  \n",
       "PT17                                    None                         Yes  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_original = pd.read_excel(path_to_data, index_col=0)\n",
    "dataset_original.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Features reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_to_drop = ['Concelho', 'HighestAgriculturalEducationalDegree']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset_original.drop(features_to_drop, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AdoptedSBP</th>\n",
       "      <th>PastureSurface</th>\n",
       "      <th>CattlePercentage</th>\n",
       "      <th>Distrito</th>\n",
       "      <th>FarmerSince</th>\n",
       "      <th>PercentRentedLand</th>\n",
       "      <th>LegalForm</th>\n",
       "      <th>HighestEducationalDegree</th>\n",
       "      <th>ExpectationFamilySuccession</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FARM_ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>PT02</th>\n",
       "      <td>0</td>\n",
       "      <td>364.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Setúbal</td>\n",
       "      <td>29</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Individual</td>\n",
       "      <td>Undergraduate</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PT13</th>\n",
       "      <td>1</td>\n",
       "      <td>542.58</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Portalegre</td>\n",
       "      <td>11</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Associated</td>\n",
       "      <td>Undergraduate</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PT15</th>\n",
       "      <td>1</td>\n",
       "      <td>262.70</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Portalegre</td>\n",
       "      <td>11</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Associated</td>\n",
       "      <td>Undergraduate</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PT16</th>\n",
       "      <td>0</td>\n",
       "      <td>23.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Évora</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Individual</td>\n",
       "      <td>Undergraduate</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PT17</th>\n",
       "      <td>1</td>\n",
       "      <td>250.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Évora</td>\n",
       "      <td>10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Associated</td>\n",
       "      <td>Undergraduate</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         AdoptedSBP  PastureSurface  CattlePercentage    Distrito  \\\n",
       "FARM_ID                                                             \n",
       "PT02              0          364.00               0.0     Setúbal   \n",
       "PT13              1          542.58               1.0  Portalegre   \n",
       "PT15              1          262.70               1.0  Portalegre   \n",
       "PT16              0           23.00               1.0       Évora   \n",
       "PT17              1          250.00               1.0       Évora   \n",
       "\n",
       "         FarmerSince  PercentRentedLand   LegalForm HighestEducationalDegree  \\\n",
       "FARM_ID                                                                        \n",
       "PT02              29                0.0  Individual            Undergraduate   \n",
       "PT13              11                0.0  Associated            Undergraduate   \n",
       "PT15              11                1.0  Associated            Undergraduate   \n",
       "PT16               3                1.0  Individual            Undergraduate   \n",
       "PT17              10                1.0  Associated            Undergraduate   \n",
       "\n",
       "        ExpectationFamilySuccession  \n",
       "FARM_ID                              \n",
       "PT02                            Yes  \n",
       "PT13                            Yes  \n",
       "PT15                            Yes  \n",
       "PT16                            Yes  \n",
       "PT17                            Yes  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_att = dataset.drop('AdoptedSBP', axis=1)\n",
    "labels = dataset['AdoptedSBP'].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Categorical attributes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ordinal encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "ordinal_attributes = ['HighestEducationalDegree']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "\n",
    "ordinal_encoder_education = OrdinalEncoder(categories=[['Primary', 'Secondary', 'Undergraduate', 'Graduate']])"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "ordinal_cat = dataset_att[ordinal_attributes]\n",
    "ordinal_cat_encoded = ordinal_encoder_education.fit_transform(ordinal_cat)\n",
    "print(ordinal_cat[:5].values, ordinal_cat_encoded[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One-hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "onehot_attributes = ['Distrito']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<30x5 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 30 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "onehot_encoder = OneHotEncoder()\n",
    "onehot_encoder.fit_transform(dataset_att[onehot_attributes])"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "onehot_cat = dataset_att[onehot_attributes]\n",
    "onehot_cat_encoded = onehot_encoder.fit_transform(onehot_cat)\n",
    "print(onehot_cat[:5].values, onehot_cat_encoded.toarray()[:5], onehot_encoder.categories_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Binary attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "binary_attributes = ['ExpectationFamilySuccession', 'LegalForm']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Numerical attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['PastureSurface', 'CattlePercentage', 'Distrito', 'FarmerSince',\n",
       "       'PercentRentedLand', 'LegalForm', 'HighestEducationalDegree',\n",
       "       'ExpectationFamilySuccession'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_att.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_attributes = [feat for feat in dataset_att.columns if (\n",
    "    (feat not in ordinal_attributes) and (feat not in onehot_attributes) and (feat not in binary_attributes)\n",
    ")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['PastureSurface', 'CattlePercentage', 'FarmerSince', 'PercentRentedLand']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numerical_attributes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparation pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.compose import ColumnTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "preparation_pipeline = ColumnTransformer([\n",
    "    ('num', StandardScaler(), numerical_attributes),\n",
    "    ('ord_cat_edu', ordinal_encoder_education, ['HighestEducationalDegree']),\n",
    "    ('other_ord_cat', OrdinalEncoder(), binary_attributes),\n",
    "    ('onehot_cat', onehot_encoder, onehot_attributes)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_prep = preparation_pipeline.fit_transform(dataset_att)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract all attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "attributes = (numerical_attributes\n",
    "              + ['HighestEducationalDegree']\n",
    "              + binary_attributes)\n",
    "for cat_name in onehot_encoder.categories_:\n",
    "    attributes += cat_name.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PastureSurface</th>\n",
       "      <th>CattlePercentage</th>\n",
       "      <th>FarmerSince</th>\n",
       "      <th>PercentRentedLand</th>\n",
       "      <th>HighestEducationalDegree</th>\n",
       "      <th>ExpectationFamilySuccession</th>\n",
       "      <th>LegalForm</th>\n",
       "      <th>Beja</th>\n",
       "      <th>Portalegre</th>\n",
       "      <th>Santarém</th>\n",
       "      <th>Setúbal</th>\n",
       "      <th>Évora</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FARM_ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>PT02</th>\n",
       "      <td>-0.239190</td>\n",
       "      <td>-2.378406</td>\n",
       "      <td>1.146256</td>\n",
       "      <td>-0.615057</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PT13</th>\n",
       "      <td>0.054486</td>\n",
       "      <td>0.556318</td>\n",
       "      <td>-0.444948</td>\n",
       "      <td>-0.615057</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PT15</th>\n",
       "      <td>-0.405778</td>\n",
       "      <td>0.556318</td>\n",
       "      <td>-0.444948</td>\n",
       "      <td>1.858870</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PT16</th>\n",
       "      <td>-0.799967</td>\n",
       "      <td>0.556318</td>\n",
       "      <td>-1.152150</td>\n",
       "      <td>1.858870</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PT17</th>\n",
       "      <td>-0.426663</td>\n",
       "      <td>0.556318</td>\n",
       "      <td>-0.533348</td>\n",
       "      <td>1.858870</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         PastureSurface  CattlePercentage  FarmerSince  PercentRentedLand  \\\n",
       "FARM_ID                                                                     \n",
       "PT02          -0.239190         -2.378406     1.146256          -0.615057   \n",
       "PT13           0.054486          0.556318    -0.444948          -0.615057   \n",
       "PT15          -0.405778          0.556318    -0.444948           1.858870   \n",
       "PT16          -0.799967          0.556318    -1.152150           1.858870   \n",
       "PT17          -0.426663          0.556318    -0.533348           1.858870   \n",
       "\n",
       "         HighestEducationalDegree  ExpectationFamilySuccession  LegalForm  \\\n",
       "FARM_ID                                                                     \n",
       "PT02                          2.0                          1.0        1.0   \n",
       "PT13                          2.0                          1.0        0.0   \n",
       "PT15                          2.0                          1.0        0.0   \n",
       "PT16                          2.0                          1.0        1.0   \n",
       "PT17                          2.0                          1.0        0.0   \n",
       "\n",
       "         Beja  Portalegre  Santarém  Setúbal  Évora  \n",
       "FARM_ID                                              \n",
       "PT02      0.0         0.0       0.0      1.0    0.0  \n",
       "PT13      0.0         1.0       0.0      0.0    0.0  \n",
       "PT15      0.0         1.0       0.0      0.0    0.0  \n",
       "PT16      0.0         0.0       0.0      0.0    1.0  \n",
       "PT17      0.0         0.0       0.0      0.0    1.0  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print prepared data as a DataFrame\n",
    "pd.DataFrame(dataset_prep, columns=attributes, index=dataset_att.index).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions for model analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_validate, cross_val_predict\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score, f1_score, precision_recall_curve, roc_curve, log_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_scores(scores, score_name):\n",
    "    #print(score_name + ' scores:', scores)\n",
    "    print(score_name + ' mean:', scores.mean())\n",
    "    #print(score_name + ' stdv:', scores.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_val_scores(clsf, dataset_prepared, labels):\n",
    "    #metrics = ['neg_log_loss', 'roc_auc', 'accuracy', 'f1', 'average_precision', 'precision', 'recall']\n",
    "    #metric_names = ['negative log loss', 'ROC AUC', 'accuracy', 'f1 score', 'average precision / PR AUC', 'precision', 'recall']\n",
    "    metrics = ['f1']\n",
    "    metric_names = ['f1 score']\n",
    "    scores = cross_validate(clsf, dataset_prepared, labels,\n",
    "                            scoring=metrics, \n",
    "                            cv=cross_val_split)\n",
    "    \n",
    "    cv_scores = {}\n",
    "    for (name, metric)  in zip(metric_names, metrics):\n",
    "        cv_scores[name] = scores['test_' + metric]\n",
    "    return cv_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_train_set(clsf, dataset_prepared, labels):\n",
    "    clsf.fit(dataset_prepared, labels)\n",
    "    pred_probs = clsf.predict_proba(dataset_prepared)[:, 1]\n",
    "    pred_classes = pred_probs >= 0.5\n",
    "    #ll = log_loss(labels, pred_probs)\n",
    "    #auc = roc_auc_score(labels, pred_probs)\n",
    "    #acc = accuracy_score(labels, pred_classes)\n",
    "    f1 = f1_score(labels, pred_classes)\n",
    "\n",
    "    print('Prediction on training set results')\n",
    "    #print('negative log loss score:', -ll)\n",
    "    #print('ROC AUC score:', auc)\n",
    "    #print('accuracy score:', acc)\n",
    "    print('f1 score:', f1)\n",
    "    \n",
    "    #train_scores = {'log loss': ll, 'ROC AUC': auc, 'accuracy': acc, 'f1 score': f1}\n",
    "    train_scores = {'f1 score': f1}\n",
    "    return train_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import clone\n",
    "\n",
    "def test_classifier(clsf, dataset_prepared, labels):  \n",
    "    \"\"\"\n",
    "    Function to:\n",
    "    - train a classifier using cross validation, reporting performance measures\n",
    "    - get classifier's predictions on the training set, to check it for overfiting\n",
    "    \"\"\"\n",
    "    clsf_copy = clone(clsf) \n",
    "    cv_scores = cross_val_scores(clsf_copy, dataset_prepared, labels)\n",
    "    print(\"Cross validation scores\")\n",
    "    for score_name, score_value in cv_scores.items():\n",
    "        display_scores(score_value, score_name)\n",
    "    print(\"\")\n",
    "    \n",
    "    train_scores = predict_train_set(clsf_copy, dataset_prepared, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## All features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import RandomizedSearchCV, StratifiedKFold\n",
    "from scipy.stats import reciprocal, uniform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_val_split = StratifiedKFold(n_splits=3, shuffle=True)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "log_reg = LogisticRegression()\n",
    "\n",
    "param_grid = {\n",
    "    #\"tol\": [5e-4],\n",
    "    \"max_iter\": [5000],\n",
    "    \"penalty\": [\"elasticnet\"],\n",
    "    \"solver\": [\"saga\"],\n",
    "    \"l1_ratio\": uniform(0., 1.),\n",
    "    \"C\": reciprocal(0.001, 100)\n",
    "    }\n",
    "\n",
    "rnd_search_log_reg = RandomizedSearchCV(log_reg, param_grid, cv=cross_val_split, n_iter=1000,\n",
    "                                        scoring=['neg_log_loss', 'roc_auc', 'accuracy', 'f1'], refit='neg_log_loss',\n",
    "                                        return_train_score=True, verbose=1)\n",
    "\n",
    "rnd_search_log_reg.fit(dataset_prep, labels)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "best_log_reg = rnd_search_log_reg.best_estimator_\n",
    "best_log_reg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 641,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration number 0 completed.\n",
      "Iteration number 1 completed.\n",
      "Iteration number 2 completed.\n",
      "Iteration number 3 completed.\n",
      "Iteration number 4 completed.\n",
      "Iteration number 5 completed.\n",
      "Iteration number 6 completed.\n",
      "Iteration number 7 completed.\n",
      "Iteration number 8 completed.\n",
      "Iteration number 9 completed.\n",
      "Iteration number 10 completed.\n",
      "Iteration number 11 completed.\n",
      "Iteration number 12 completed.\n",
      "Iteration number 13 completed.\n",
      "Iteration number 14 completed.\n",
      "Iteration number 15 completed.\n",
      "Iteration number 16 completed.\n",
      "Iteration number 17 completed.\n",
      "Iteration number 18 completed.\n",
      "Iteration number 19 completed.\n",
      "Iteration number 20 completed.\n",
      "Iteration number 21 completed.\n",
      "Iteration number 22 completed.\n",
      "Iteration number 23 completed.\n",
      "Iteration number 24 completed.\n",
      "Iteration number 25 completed.\n",
      "Iteration number 26 completed.\n",
      "Iteration number 27 completed.\n",
      "Iteration number 28 completed.\n",
      "Iteration number 29 completed.\n"
     ]
    }
   ],
   "source": [
    "# Nested cross-validation to try different split into train and test set\n",
    "log_reg = LogisticRegression()\n",
    "\n",
    "param_grid = {\n",
    "    #\"tol\": [5e-4],\n",
    "    \"max_iter\": [5000],\n",
    "    \"penalty\": [\"elasticnet\"],\n",
    "    \"solver\": [\"saga\"],\n",
    "    \"l1_ratio\": uniform(0., 1.),\n",
    "    \"C\": uniform(0.001, 1)\n",
    "    }\n",
    "\n",
    "NUM_TRIALS = 30\n",
    "rnd_srch_results = {}\n",
    "for i in range(NUM_TRIALS):\n",
    "     cv = StratifiedKFold(n_splits=3, shuffle=True, random_state=i)\n",
    "     rnd_srch = RandomizedSearchCV(log_reg, param_grid, cv=cv_split, n_iter=1000,\n",
    "                                  scoring='f1', return_train_score=True, verbose=0)\n",
    "     rnd_srch.fit(dataset_prep, labels)\n",
    "     rnd_srch_results[rnd_srch.best_estimator_] = rnd_srch.best_score_\n",
    "     print(\"Iteration number\", str(i), \"completed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 650,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_values([0.7222222222222222, 0.7222222222222222, 0.7222222222222222, 0.7222222222222222, 0.7222222222222222, 0.7222222222222222, 0.7222222222222222, 0.7222222222222222, 0.7222222222222222, 0.7222222222222222, 0.7222222222222222, 0.7222222222222222, 0.7222222222222222, 0.7222222222222222, 0.7222222222222222, 0.7222222222222222, 0.7222222222222222, 0.7222222222222222, 0.7222222222222222, 0.7222222222222222, 0.7222222222222222, 0.7222222222222222, 0.7222222222222222, 0.7222222222222222, 0.7222222222222222, 0.7222222222222222, 0.7222222222222222, 0.7222222222222222, 0.7222222222222222, 0.7222222222222222])"
      ]
     },
     "execution_count": 650,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnd_srch_results.values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 651,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7222222222222222"
      ]
     },
     "execution_count": 651,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_score = max(rnd_srch_results.values())\n",
    "best_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 652,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[LogisticRegression(C=0.18420009497390522, l1_ratio=0.8798503520474761,\n",
       "                    max_iter=5000, penalty='elasticnet', solver='saga'),\n",
       " LogisticRegression(C=0.15314534840090865, l1_ratio=0.7678299455403869,\n",
       "                    max_iter=5000, penalty='elasticnet', solver='saga'),\n",
       " LogisticRegression(C=0.17750873563564762, l1_ratio=0.9154102173849715,\n",
       "                    max_iter=5000, penalty='elasticnet', solver='saga'),\n",
       " LogisticRegression(C=0.21511936934400033, l1_ratio=0.9978175997771237,\n",
       "                    max_iter=5000, penalty='elasticnet', solver='saga'),\n",
       " LogisticRegression(C=0.09204863617862546, l1_ratio=0.6613775331282453,\n",
       "                    max_iter=5000, penalty='elasticnet', solver='saga'),\n",
       " LogisticRegression(C=0.05634322030912864, l1_ratio=0.35866453265846854,\n",
       "                    max_iter=5000, penalty='elasticnet', solver='saga'),\n",
       " LogisticRegression(C=0.16303404355076823, l1_ratio=0.689482669064816,\n",
       "                    max_iter=5000, penalty='elasticnet', solver='saga'),\n",
       " LogisticRegression(C=0.07745723687715245, l1_ratio=0.40006499133149886,\n",
       "                    max_iter=5000, penalty='elasticnet', solver='saga'),\n",
       " LogisticRegression(C=0.12792074497610884, l1_ratio=0.920567795734127,\n",
       "                    max_iter=5000, penalty='elasticnet', solver='saga'),\n",
       " LogisticRegression(C=0.06458502057178805, l1_ratio=0.5870658969609209,\n",
       "                    max_iter=5000, penalty='elasticnet', solver='saga'),\n",
       " LogisticRegression(C=0.1392745863741931, l1_ratio=0.6195967507257586,\n",
       "                    max_iter=5000, penalty='elasticnet', solver='saga'),\n",
       " LogisticRegression(C=0.001453279180559707, l1_ratio=0.28622938777913465,\n",
       "                    max_iter=5000, penalty='elasticnet', solver='saga'),\n",
       " LogisticRegression(C=0.003530651518025895, l1_ratio=0.30174341894861123,\n",
       "                    max_iter=5000, penalty='elasticnet', solver='saga'),\n",
       " LogisticRegression(C=0.053940560962495665, l1_ratio=0.25309233219988636,\n",
       "                    max_iter=5000, penalty='elasticnet', solver='saga'),\n",
       " LogisticRegression(C=0.04601302271577168, l1_ratio=0.48664107099496057,\n",
       "                    max_iter=5000, penalty='elasticnet', solver='saga'),\n",
       " LogisticRegression(C=0.13040102841953383, l1_ratio=0.7510116818911377,\n",
       "                    max_iter=5000, penalty='elasticnet', solver='saga'),\n",
       " LogisticRegression(C=0.015154817649470687, l1_ratio=0.2043253097641966,\n",
       "                    max_iter=5000, penalty='elasticnet', solver='saga'),\n",
       " LogisticRegression(C=0.13051344637853568, l1_ratio=0.8939151603484162,\n",
       "                    max_iter=5000, penalty='elasticnet', solver='saga'),\n",
       " LogisticRegression(C=0.09920325808116792, l1_ratio=0.4072678400561659,\n",
       "                    max_iter=5000, penalty='elasticnet', solver='saga'),\n",
       " LogisticRegression(C=0.11130278623724699, l1_ratio=0.5755383705622346,\n",
       "                    max_iter=5000, penalty='elasticnet', solver='saga'),\n",
       " LogisticRegression(C=0.12940843086591491, l1_ratio=0.9578041423947805,\n",
       "                    max_iter=5000, penalty='elasticnet', solver='saga'),\n",
       " LogisticRegression(C=0.02447320505820194, l1_ratio=0.6036029779858861,\n",
       "                    max_iter=5000, penalty='elasticnet', solver='saga'),\n",
       " LogisticRegression(C=0.0827464072373928, l1_ratio=0.39850171246823685,\n",
       "                    max_iter=5000, penalty='elasticnet', solver='saga'),\n",
       " LogisticRegression(C=0.10815289957570073, l1_ratio=0.6716581743804099,\n",
       "                    max_iter=5000, penalty='elasticnet', solver='saga'),\n",
       " LogisticRegression(C=0.07541214993702228, l1_ratio=0.7188112442465212,\n",
       "                    max_iter=5000, penalty='elasticnet', solver='saga'),\n",
       " LogisticRegression(C=0.04213488241389973, l1_ratio=0.42899725728680804,\n",
       "                    max_iter=5000, penalty='elasticnet', solver='saga'),\n",
       " LogisticRegression(C=0.1024493762009171, l1_ratio=0.9536451603715715,\n",
       "                    max_iter=5000, penalty='elasticnet', solver='saga'),\n",
       " LogisticRegression(C=0.01286878239229905, l1_ratio=0.05484860956510562,\n",
       "                    max_iter=5000, penalty='elasticnet', solver='saga'),\n",
       " LogisticRegression(C=0.07001021346032421, l1_ratio=0.6765497450182547,\n",
       "                    max_iter=5000, penalty='elasticnet', solver='saga'),\n",
       " LogisticRegression(C=0.18240434821919949, l1_ratio=0.8245025300542723,\n",
       "                    max_iter=5000, penalty='elasticnet', solver='saga')]"
      ]
     },
     "execution_count": 652,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_models = [k for k, v in rnd_srch_results.items() if v == best_score]\n",
    "best_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 653,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_log_reg = best_models[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 654,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1], dtype=int64)"
      ]
     },
     "execution_count": 654,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_log_reg.predict(dataset_prep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 655,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0 PastureSurface\n",
      "0.0 CattlePercentage\n",
      "0.0 FarmerSince\n",
      "0.0 PercentRentedLand\n",
      "0.0 HighestEducationalDegree\n",
      "0.0 ExpectationFamilySuccession\n",
      "0.0 LegalForm\n",
      "0.0 Beja\n",
      "0.0 Portalegre\n",
      "0.0 Santarém\n",
      "0.0 Setúbal\n",
      "0.0 Évora\n"
     ]
    }
   ],
   "source": [
    "for attr, coef in zip(attributes, best_log_reg.coef_.tolist()[0]):\n",
    "    print(coef, attr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 656,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross validation scores\n",
      "f1 score mean: 0.7222222222222222\n",
      "\n",
      "Prediction on training set results\n",
      "f1 score: 0.7234042553191489\n"
     ]
    }
   ],
   "source": [
    "test_classifier(best_log_reg, dataset_prep, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reduced number of features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_attributes_red = ['PastureSurface', 'PercentRentedLand']\n",
    "binary_attributes_red = ['LegalForm']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "preparation_pipeline_red = ColumnTransformer([\n",
    "    ('num', StandardScaler(), numerical_attributes_red),\n",
    "    ('ord_cat_edu', ordinal_encoder_education, ['HighestEducationalDegree']),\n",
    "    ('other_ord_cat', OrdinalEncoder(), binary_attributes_red),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_prep_red = preparation_pipeline_red.fit_transform(dataset_att)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "attributes_red = (numerical_attributes_red + ['HighestEducationalDegree'] + binary_attributes_red)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "log_reg = LogisticRegression(random_state=42)\n",
    "\n",
    "param_grid = {\n",
    "    \"tol\": [1e-5],\n",
    "    \"max_iter\": [10000],\n",
    "    \"penalty\": [\"elasticnet\"],\n",
    "    \"solver\": [\"saga\"],\n",
    "    \"l1_ratio\": np.arange(0., 1., 0.1),\n",
    "    #\"C\": [0.01, 0.1, 1, 10, 100, 1000]\n",
    "    \"C\": np.arange(0.01, 0.03, 0.001)\n",
    "    #\"C\": np.arange(0.00001, 0.0001, 0.00011)\n",
    "    }\n",
    "\n",
    "grid_search_log_reg_red = GridSearchCV(log_reg, param_grid, cv=cross_val_split,\n",
    "                                       scoring=['neg_log_loss', 'roc_auc', 'accuracy', 'f1'], refit='neg_log_loss',\n",
    "                                       return_train_score=True, verbose=1)\n",
    "\n",
    "grid_search_log_reg_red.fit(dataset_prep_red, labels)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "best_log_reg_red = rnd_search_log_reg_red.best_estimator_\n",
    "best_log_reg_red"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration number 0 completed.\n",
      "Iteration number 1 completed.\n",
      "Iteration number 2 completed.\n",
      "Iteration number 3 completed.\n",
      "Iteration number 4 completed.\n",
      "Iteration number 5 completed.\n",
      "Iteration number 6 completed.\n",
      "Iteration number 7 completed.\n",
      "Iteration number 8 completed.\n",
      "Iteration number 9 completed.\n",
      "Iteration number 10 completed.\n",
      "Iteration number 11 completed.\n",
      "Iteration number 12 completed.\n",
      "Iteration number 13 completed.\n",
      "Iteration number 14 completed.\n",
      "Iteration number 15 completed.\n",
      "Iteration number 16 completed.\n",
      "Iteration number 17 completed.\n",
      "Iteration number 18 completed.\n",
      "Iteration number 19 completed.\n",
      "Iteration number 20 completed.\n",
      "Iteration number 21 completed.\n",
      "Iteration number 22 completed.\n",
      "Iteration number 23 completed.\n",
      "Iteration number 24 completed.\n",
      "Iteration number 25 completed.\n",
      "Iteration number 26 completed.\n",
      "Iteration number 27 completed.\n",
      "Iteration number 28 completed.\n",
      "Iteration number 29 completed.\n"
     ]
    }
   ],
   "source": [
    "# Nested cross-validation to try different split into train and test set\n",
    "log_reg = LogisticRegression()\n",
    "\n",
    "param_grid = {\n",
    "    #\"tol\": [5e-4],\n",
    "    \"max_iter\": [5000],\n",
    "    \"penalty\": [\"elasticnet\"],\n",
    "    \"solver\": [\"saga\"],\n",
    "    \"l1_ratio\": uniform(0., 1.),\n",
    "    \"C\": reciprocal(0.001, 1)\n",
    "    }\n",
    "\n",
    "NUM_TRIALS = 30\n",
    "rnd_srch_results_red = {}\n",
    "for i in range(NUM_TRIALS):\n",
    "     cv_split = StratifiedKFold(n_splits=3, shuffle=True, random_state=i)\n",
    "     rnd_srch = RandomizedSearchCV(log_reg, param_grid, cv=cv_split, n_iter=1000,\n",
    "                                  scoring='f1', return_train_score=True, verbose=0)\n",
    "     rnd_srch.fit(dataset_prep_red, labels)\n",
    "     rnd_srch_results_red[rnd_srch.best_estimator_] = rnd_srch.best_score_\n",
    "     print(\"Iteration number\", str(i), \"completed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_values([0.7222222222222222, 0.7261904761904762, 0.738095238095238, 0.7222222222222222, 0.7428571428571429, 0.7222222222222222, 0.7388888888888889, 0.7222222222222222, 0.7269841269841271, 0.7222222222222222, 0.7428571428571429, 0.7222222222222222, 0.7388888888888889, 0.7472527472527473, 0.7222222222222222, 0.7222222222222222, 0.7222222222222222, 0.7428571428571429, 0.7509157509157509, 0.7222222222222222, 0.7286324786324787, 0.7222222222222222, 0.7388888888888889, 0.7388888888888889, 0.7388888888888889, 0.7388888888888889, 0.7269841269841271, 0.7388888888888889, 0.7222222222222222, 0.7222222222222222])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnd_srch_results_red.values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7509157509157509"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_score_red = max(rnd_srch_results_red.values())\n",
    "best_score_red"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[LogisticRegression(C=0.5159745211945587, l1_ratio=0.033494396058209475,\n",
       "                    max_iter=5000, penalty='elasticnet', solver='saga')]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_models_red = [k for k, v in rnd_srch_results_red.items() if v == best_score_red]\n",
    "best_models_red"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_log_reg_red = best_models_red[0]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "best_log_reg_red = list(rnd_srch_results_red.keys())[0]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "best_log_reg_red"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 0, 1, 1], dtype=int64)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_log_reg_red.predict(dataset_prep_red)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1649394077264545 PastureSurface\n",
      "-0.23522868039886305 PercentRentedLand\n",
      "0.16962977865355552 HighestEducationalDegree\n",
      "-0.3296090864746737 LegalForm\n"
     ]
    }
   ],
   "source": [
    "for attr, coef in zip(attributes_red, best_log_reg_red.coef_.tolist()[0]):\n",
    "    print(coef, attr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.02515551])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_log_reg_red.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross validation scores\n",
      "f1 score mean: 0.6151515151515151\n",
      "\n",
      "Prediction on training set results\n",
      "f1 score: 0.7\n"
     ]
    }
   ],
   "source": [
    "test_classifier(best_log_reg_red, dataset_prep_red, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic regression selected on whole training set with 4 variables (same as FL Calibrated ABM)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "log_reg = LogisticRegression()\n",
    "\n",
    "param_grid = {\n",
    "    #\"tol\": [5e-4],\n",
    "    \"max_iter\": [5000],\n",
    "    \"penalty\": [\"elasticnet\"],\n",
    "    \"solver\": [\"saga\"],\n",
    "    \"l1_ratio\": uniform(0., 1.),\n",
    "    \"C\": uniform(0.001, 1)\n",
    "    }\n",
    "\n",
    "rnd_search_log_reg_nocv = RandomizedSearchCV(log_reg, param_grid, cv=[(slice(None), slice(None))], n_iter=10000,\n",
    "                                              scoring='f1', return_train_score=True, verbose=0)\n",
    "\n",
    "rnd_search_log_reg_nocv.fit(dataset_prep_red, labels)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "best_log_reg_nocv = rnd_search_log_reg_nocv.best_estimator_\n",
    "best_log_reg_nocv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import ParameterSampler\n",
    "from sklearn.base import clone\n",
    "\n",
    "def RandomizedSearch(estimator, param_distribution, n_iter, X, y):\n",
    "    best_f1 = 0\n",
    "    best_model = None\n",
    "    for g in ParameterSampler(param_distribution, n_iter):\n",
    "        estimator.set_params(**g)\n",
    "        estimator.fit(X, y)\n",
    "        # get score and save if best\n",
    "        preds = estimator.predict(X)\n",
    "        f1 = f1_score(y, preds)\n",
    "        if f1 > best_f1:\n",
    "            best_f1 = f1\n",
    "            best_model = clone(estimator)\n",
    "    best_model.fit(X, y)\n",
    "    return (best_model, best_f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_reg = LogisticRegression()\n",
    "\n",
    "param_grid = {\n",
    "    #\"tol\": [5e-4],\n",
    "    \"max_iter\": [5000],\n",
    "    \"penalty\": [\"elasticnet\"],\n",
    "    \"solver\": [\"saga\"],\n",
    "    \"l1_ratio\": uniform(0., 1.),\n",
    "    \"C\": uniform(0.001, 1)\n",
    "    }\n",
    "\n",
    "best_log_reg_nocv, best_f1 = RandomizedSearch(log_reg, param_grid, 10000, dataset_prep_red, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=0.2011450499485996, l1_ratio=0.3034600016432272,\n",
       "                   max_iter=5000, penalty='elasticnet', solver='saga')"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_log_reg_nocv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1], dtype=int64)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_log_reg_nocv.predict(dataset_prep_red)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.06431054471062879 PastureSurface\n",
      "-0.11718656859772143 PercentRentedLand\n",
      "0.009297341584584468 HighestEducationalDegree\n",
      "0.0 LegalForm\n"
     ]
    }
   ],
   "source": [
    "for attr, coef in zip(attributes_red, best_log_reg_nocv.coef_.tolist()[0]):\n",
    "    print(coef, attr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.24807761])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_log_reg_nocv.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross validation scores\n",
      "f1 score mean: 0.7222222222222222\n",
      "\n",
      "Prediction on training set results\n",
      "f1 score: 0.7555555555555554\n"
     ]
    }
   ],
   "source": [
    "test_classifier(best_log_reg_nocv, dataset_prep_red, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trial with random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 640,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 100 candidates, totalling 300 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 300 out of 300 | elapsed:  2.1min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=KFold(n_splits=3, random_state=42, shuffle=True),\n",
       "                   estimator=RandomForestClassifier(n_jobs=-1), n_iter=100,\n",
       "                   param_distributions={'max_depth': array([1, 2, 3, 4]),\n",
       "                                        'max_leaf_nodes': array([ 2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17, 18,\n",
       "       19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n",
       "       36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52,\n",
       "       53, 54, 5...\n",
       "                                        'n_estimators': array([ 2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17, 18,\n",
       "       19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n",
       "       36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52,\n",
       "       53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69,\n",
       "       70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86,\n",
       "       87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99])},\n",
       "                   return_train_score=True, scoring='f1', verbose=1)"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnd_clsf = RandomForestClassifier(n_jobs=-1)\n",
    "\n",
    "param_grid = {\n",
    "    \"n_estimators\": np.arange(2, 100, 1),\n",
    "    \"max_depth\": np.arange(1, 5, 1),\n",
    "    \"min_samples_leaf\": np.arange(2, 30, 1),\n",
    "    \"min_samples_split\": np.arange(2, 30, 1),\n",
    "    \"max_leaf_nodes\": np.arange(2, 100, 1)\n",
    "    }\n",
    "        \n",
    "grid_search_rnd_clsf = RandomizedSearchCV(rnd_clsf, param_grid, cv=cross_val_split, n_iter=100,\n",
    "                                    scoring='f1',\n",
    "                                    return_train_score=True, verbose=1)\n",
    "\n",
    "grid_search_rnd_clsf.fit(dataset_prep, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(max_depth=1, max_leaf_nodes=92, min_samples_leaf=5,\n",
       "                       min_samples_split=11, n_estimators=22, n_jobs=-1)"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best = grid_search_rnd_clsf.best_estimator_\n",
    "best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1], dtype=int64)"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best.predict(dataset_prep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7286324786324787"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search_rnd_clsf.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.13636363636363635 PastureSurface\n",
      "0.045454545454545456 CattlePercentage\n",
      "0.09090909090909091 FarmerSince\n",
      "0.13636363636363635 PercentRentedLand\n",
      "0.09090909090909091 HighestEducationalDegree\n",
      "0.045454545454545456 ExpectationFamilySuccession\n",
      "0.22727272727272727 LegalForm\n",
      "0.13636363636363635 Beja\n",
      "0.0 Portalegre\n",
      "0.0 Santarém\n",
      "0.0 Setúbal\n",
      "0.09090909090909091 Évora\n"
     ]
    }
   ],
   "source": [
    "for attr, coef in zip(attributes, best.feature_importances_.tolist()):\n",
    "    print(coef, attr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross validation scores\n",
      "negative log loss mean: -0.7090943212578465\n",
      "negative log loss stdv: 0.026601056056504573\n",
      "ROC AUC mean: 0.5002777777777778\n",
      "ROC AUC stdv: 0.029268341300270756\n",
      "accuracy mean: 0.5\n",
      "accuracy stdv: 0.08164965809277258\n",
      "f1 score mean: 0.6055555555555555\n",
      "f1 score stdv: 0.14927809825049332\n",
      "average precision / PR AUC mean: 0.6582451499118165\n",
      "average precision / PR AUC stdv: 0.10584216774723841\n",
      "precision mean: 0.5185185185185185\n",
      "precision stdv: 0.08574694002066832\n",
      "recall mean: 0.7444444444444445\n",
      "recall stdv: 0.2528845928164676\n",
      "\n",
      "Prediction on training set results\n",
      "negative log loss score: -0.6275624571275097\n",
      "ROC AUC score: 0.7013574660633485\n",
      "accuracy score: 0.6\n",
      "f1 score: 0.7\n"
     ]
    }
   ],
   "source": [
    "test_classifier(best, dataset_prep_red, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data_analysis",
   "language": "python",
   "name": "data_analysis"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
